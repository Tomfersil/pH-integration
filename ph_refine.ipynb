{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c0b8ab",
   "metadata": {},
   "source": [
    "## Ensemble refinement for pH\n",
    "\n",
    "Tools for the refinement of systems with observables measured at different pH values.\n",
    "\n",
    "Ensemble refinement only.\n",
    "\n",
    "This will be implemented as a module `ph_refine` of the Python package `MDRefine`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da6b6f",
   "metadata": {},
   "source": [
    "### Theory (loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7166877",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathcal L (\\{ P_j\\}, \\vec\\pi) =\n",
    "\\frac{1}{2}\\sum_{k=1}^{N_{obs}}\\sum_{\\substack{i=1\\\\i\\in \\sigma(k)}}^{N_{ph}} \\Bigl( \\frac{\\sum_j w_{ij} \\langle g_k \\rangle_{P_j} - g_{ik,exp}}{\\sigma_{ik,exp}}\\Bigr)^2 + \\sum_j \\alpha_j D_{KL}[P_j||P_{0j}] + \\alpha D_{KL}[\\vec\\pi | \\vec \\pi_0]\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "with normalization of $P_j(x)$, $\\vec\\pi$ and $w_{ij}$ (the relation between $w_{ij}$ and $\\pi_j$ is given by the grand-canonical ensemble; also $\\alpha_j$ might depend on $\\vec\\pi$, for example as $\\alpha_j = \\alpha \\pi_j$, but perhaps it has more physical meaning to keep all them $\\alpha_j = \\alpha$).\n",
    "\n",
    "Minimizing this loss function over the ensembles $P_j$ is equivalent to maximize the following loss function (same spirit of $\\tilde\\Gamma$) over the $\\vec\\lambda$ coefficients (one for each $g_{exp}$ value, independently on the number of protonation states $\\#\\{P_j\\}$):\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\tilde{\\mathcal L} (\\vec\\lambda, \\vec\\pi) & \n",
    "= -\\sum_k \\sum_{i, i\\in \\sigma(k)} \\Bigl( \\frac{1}{2} \\sigma_{ki,exp}^2 \\lambda_{ki}^2 + \\lambda_{ki} g_{ki,exp} \\Bigr) - \\sum_j \\log Z_j(\\vec\\lambda, \\vec\\pi) + \\alpha D_{KL}[\\vec\\pi || \\vec\\pi_0] \\\\\n",
    "& = - \\Gamma(\\vec\\lambda;\\vec\\pi) + \\alpha D_{KL}[\\vec\\pi || \\vec\\pi_0]\n",
    "\\tag{2}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "where the ensemble $P_j$ is parametrized by $\\lambda$ as\n",
    "\n",
    "\\begin{equation}\n",
    "P_j(x;\\vec\\lambda) = \\frac{1}{Z_j(\\vec\\lambda)} P_{0j}(x) \\, \\mathrm{exp}\\Bigl\\{-\\frac{1}{\\alpha_j} \\sum_k \\sum_{i,i\\in\\sigma(k)} \\lambda_{ki} w_{ij} g_k(x) \\Bigr\\}.\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "Notice the $\\vec\\lambda$ coefficients are present according with the experimental values, not with the structural (protonation) ensembles $P_j$.\n",
    "\n",
    "This simplifies to our usual case, in which we have experimental values corresponding to same pH value (but different molecular systems)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361ceba",
   "metadata": {},
   "source": [
    "### Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ed03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import numpy as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee796d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manage_indices():\n",
    "    \"\"\"\n",
    "    Manage experimental value indices relative to observable and pH indices.\n",
    "\n",
    "    This class relies both on `numpy` and `jax.numpy` because of filling matrices, which is not plainly\n",
    "    allowed in Jax.\n",
    "\n",
    "    This class provides utility methods for working with a 2D matrix of experimental values for example\n",
    "    (`my_exp_values`), where:\n",
    "    * The **first index** corresponds to the observable index.\n",
    "    * The **second index** corresponds to the pH index.\n",
    "\n",
    "    ### Methods\n",
    "    - **build_legend(my_exp_values)** → `(legend_matrix, legend_row)`  \n",
    "    Builds:\n",
    "    - `legend_matrix`: a 2D array where each element stores the index of the corresponding\n",
    "        value in a flattened list (`-1` if the value is absent).  \n",
    "    - `legend_row`: a 1D array storing the ending index of each observable row in the flattened data.  \n",
    "\n",
    "    - **flatten(my_exp_values)** → `flat_mat`  \n",
    "    Flattens `my_exp_values` into a 1D array of non-NaN values according to `legend_matrix`.  \n",
    "\n",
    "    - **flat_to_matrix(flat_mat, legend_matrix)** → `my_exp_values`  \n",
    "    Reconstructs the original `my_exp_values` matrix from its flattened form and the legend.  \n",
    "\n",
    "    ### Example\n",
    "    ```python\n",
    "    my_exp_values = np.array([\n",
    "        [0.1, 0.2, 0.1, np.nan, np.nan],\n",
    "        [np.nan, 0.4, 0.5, np.nan, 0.7],\n",
    "        [np.nan, np.nan, np.nan, 0.2, np.nan],\n",
    "        [0.3, 0.5, 0.8, np.nan, 0.1],\n",
    "        [np.nan, np.nan, 0.3, 0.3, np.nan]\n",
    "    ])\n",
    "\n",
    "    # Build legend\n",
    "    legend_matrix, legend_row = ManageIndices.build_legend(my_exp_values)\n",
    "\n",
    "    # Flatten and reconstruct\n",
    "    flat_mat = ManageIndices.flatten(my_exp_values)\n",
    "    mat = ManageIndices.flat_to_matrix(flat_mat, legend_matrix)\n",
    "\n",
    "    # Select values for a specific observable (row i)\n",
    "    i = 3\n",
    "    values_for_obs = flat_mat[legend_row[i] : legend_row[i + 1]]\n",
    "\n",
    "    # Example usage in a correction computation:\n",
    "    correction_lambdas = (1 / alphas[j]) * np.einsum(\n",
    "        'ki,ij,kt->jt',\n",
    "        lambdas[legend_row[i] : legend_row[i + 1]],\n",
    "        ph_weights[j],\n",
    "        g\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    This workflow is useful for handling non-trivial sums over observable and pH indices when\n",
    "    a simple 1D representation of lambdas is insufficient.\n",
    "    \"\"\"\n",
    "    def build_legend(my_exp_values):\n",
    "        a, b = my_exp_values.shape\n",
    "\n",
    "        legend_matrix = numpy.full((a, b), 0)\n",
    "        legend_row = [0]\n",
    "\n",
    "        tot = 0\n",
    "\n",
    "        for i in range(a):\n",
    "            for j in range(b):\n",
    "                if not np.isnan(my_exp_values[i, j]):\n",
    "                    legend_matrix[i, j] = tot\n",
    "                    tot += 1\n",
    "                else:\n",
    "                    legend_matrix[i, j] = -1\n",
    "\n",
    "            legend_row.append(tot)\n",
    "\n",
    "        legend_matrix = np.int32(legend_matrix)\n",
    "        legend_row = np.int32(legend_row)\n",
    "\n",
    "        return legend_matrix, legend_row\n",
    "\n",
    "    def flatten(my_exp_values):\n",
    "        flat_mat = np.ravel(my_exp_values)\n",
    "        flat_mat = flat_mat[~np.isnan(flat_mat)]\n",
    "        return flat_mat\n",
    "\n",
    "    def flat_to_matrix_old(flat_mat, legend_matrix):\n",
    "        \"\"\" It uses also NumPy, not only Jax \"\"\"\n",
    "\n",
    "        mat = numpy.full(legend_matrix.shape, np.nan)\n",
    "\n",
    "        whs = np.argwhere(legend_matrix >= 0)\n",
    "        for wh in whs: mat[wh[0], wh[1]] = flat_mat[legend_matrix[wh[0], wh[1]]]\n",
    "\n",
    "        mat = np.array(mat)\n",
    "\n",
    "        return mat\n",
    "    \n",
    "    def flat_to_matrix(flat_mat, legend_matrix):\n",
    "        \"\"\"\n",
    "        Reconstructs a matrix from its flattened representation and legend_matrix,\n",
    "        using only JAX (no Python-side assignments).\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize with NaNs\n",
    "        mat = np.full(legend_matrix.shape, np.nan)\n",
    "\n",
    "        # Indices where legend_matrix >= 0\n",
    "        whs = np.argwhere(legend_matrix >= 0)\n",
    "\n",
    "        # Values to insert: flat_mat[legend_matrix[idx]]\n",
    "        vals = flat_mat[legend_matrix[whs[:, 0], whs[:, 1]]]\n",
    "\n",
    "        # Update using JAX's immutable update API\n",
    "        mat = mat.at[whs[:, 0], whs[:, 1]].set(vals)\n",
    "\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_and_minimizer import compute_new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ph_gamma(lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights):\n",
    "    \"\"\"\n",
    "    Compute the Gamma function for the pH refinement.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    lambdas : 1-D array-like\n",
    "        Numpy 1-dimensional array, each element corresponds to the lambda value for an experimental observable\n",
    "        at a certain pH value; this correspondence is given by `Manage_indices.flatten` (from table of values\n",
    "        to 1d array) and `Manage_indices.flat_to_matrix` (from 1d array to table of values).\n",
    "    \n",
    "    legend_matrix :\n",
    "        Numpy 2-dimensional array used to map `lambdas` 1d array into the table of values by\n",
    "        `Manage_indices.flat_to_matrix` (first index is for the observable, second index for the pH).\n",
    "\n",
    "    gs : List of 2-D array-like\n",
    "        List (one element for each protonation state) of Numpy 2-dimensional arrays (M x N);\n",
    "        `g[i, j]` is the j-th observable computed in the i-th frame.\n",
    "    \n",
    "    g_exp : 2-D array-like\n",
    "        Numpy 2-dimensional array (N x 2); `g_exp[j, 0]` is the experimental value of the j-th observable,\n",
    "        `g_exp[j,1]` is the associated experimental uncertainty.\n",
    "    \n",
    "    weights_ref : List of 1-D array-like\n",
    "        List (one element for each protonation state) of Numpy 1-dimensional arrays, each of them is the\n",
    "        set of weights for the reference ensemble.\n",
    "    \n",
    "    alphas : 1-D array-like\n",
    "        Numpy 1-dimensional array for the values of the alpha hyperparameters.\n",
    "    \n",
    "    ph_weights : 2-D array-like\n",
    "        Numpy 2-dimensional array, `ph_weights[i, j]` is the probability of the protonation state `j` at pH `i`,\n",
    "        normalized over `j` for every `i`.\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "\n",
    "    gamma : float\n",
    "        Value of the pH_Gamma function (analogous to the Gamma function for the pH application).\n",
    "    \"\"\"\n",
    "    # if len(alphas) == 1:\n",
    "    # then just a single hyperparameter alpha (so, optimize over a single hyperparameter)\n",
    "    logZs = []\n",
    "    \n",
    "    n_ph = len(weights_ref)\n",
    "\n",
    "    table_lambdas = Manage_indices.flat_to_matrix(lambdas, legend_matrix)\n",
    "    table_lambdas = np.nan_to_num(table_lambdas)  # put nan to zero\n",
    "    \n",
    "    for j in range(n_ph):\n",
    "        # print(fake_lambdas.shape, ph_weights.shape, gs[j].shape)\n",
    "        # print(np.einsum('ki,i,lk', fake_lambdas, ph_weights[:, j], gs[j]))\n",
    "        correction_lambdas = 1/alphas[j]*np.einsum('ki,i,tk->t', table_lambdas, ph_weights[:, j], gs[j])\n",
    "        log_Z_lambda = compute_new_weights(weights_ref[j], correction_lambdas)[1]\n",
    "        logZs.append(log_Z_lambda)\n",
    "\n",
    "    logZs = np.array(logZs)\n",
    "    \n",
    "    gamma = 1/2*np.sum((lambdas*g_exp[:, 1])**2) + np.dot(lambdas, g_exp[:, 0]) + np.sum(logZs)\n",
    "\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd4298",
   "metadata": {},
   "source": [
    "### Simple cases of usage of the main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8451f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.2 0.1 nan nan]\n",
      " [nan 0.4 0.5 nan 0.7]\n",
      " [nan nan nan 0.2 nan]\n",
      " [0.3 0.5 0.8 nan 0.1]\n",
      " [nan nan 0.3 0.3 nan]]\n",
      "[[ 0  1  2 -1 -1]\n",
      " [-1  3  4 -1  5]\n",
      " [-1 -1 -1  6 -1]\n",
      " [ 7  8  9 -1 10]\n",
      " [-1 -1 11 12 -1]] [ 0  3  6  7 11 13]\n",
      "[0.1 0.2 0.1 0.4 0.5 0.7 0.2 0.3 0.5 0.8 0.1 0.3 0.3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[0.1, 0.2, 0.1, nan, nan],\n",
       "       [nan, 0.4, 0.5, nan, 0.7],\n",
       "       [nan, nan, nan, 0.2, nan],\n",
       "       [0.3, 0.5, 0.8, nan, 0.1],\n",
       "       [nan, nan, 0.3, 0.3, nan]], dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_exp_values = np.array([[0.1, 0.2, 0.1, np.nan, np.nan], [np.nan, 0.4, 0.5, np.nan, 0.7],\n",
    "                 [np.nan, np.nan, np.nan, 0.2, np.nan], [0.3, 0.5, 0.8, np.nan, 0.1],\n",
    "                 [np.nan, np.nan, 0.3, 0.3, np.nan]])\n",
    "\n",
    "print(my_exp_values)\n",
    "\n",
    "# so the first index in my_exp_values corresponds to the observable index, and the second to the ph index\n",
    "legend_matrix, legend_row = Manage_indices.build_legend(my_exp_values)\n",
    "\n",
    "print(legend_matrix, legend_row)\n",
    "\n",
    "flat_mat = Manage_indices.flatten(my_exp_values)\n",
    "\n",
    "print(flat_mat)\n",
    "\n",
    "mat = Manage_indices.flat_to_matrix(flat_mat, legend_matrix)\n",
    "\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c3dc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.1, 0.2, 0.1, nan, nan],\n",
       "       [nan, 0.4, 0.5, nan, 0.7],\n",
       "       [nan, nan, nan, 0.2, nan],\n",
       "       [0.3, 0.5, 0.8, nan, 0.1],\n",
       "       [nan, nan, 0.3, 0.3, nan]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manage_indices.flat_to_matrix_old(flat_mat, legend_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbfc6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.3, 0.5, 0.8, 0.1], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "\n",
    "flat_mat[legend_row[i] : legend_row[i + 1]]\n",
    "# this is the array of values corresponding to the i-th observable at different pH values\n",
    "# so that the correction is computed as \n",
    "# correction_lambdas = 1/alphas[j]*np.einsum('ki,ij,kt->jt', lambdas[legend_row[i] : legend_row[i + 1]], ph_weights[j], g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bdfba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.2 0.1 0.4 0.5 0.7 0.2 0.3 0.5 0.8 0.1 0.3 0.3] [ 0  3  6  7 11 13]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(flat_mat, legend_row)\n",
    "\n",
    "n_exp_vals = len(flat_mat)\n",
    "\n",
    "# The **first index** corresponds to the observable index, the **second index** corresponds to the pH index\n",
    "n_obs, n_ph = my_exp_values.shape\n",
    "n_prot = 2\n",
    "\n",
    "lambdas = np.ones(n_exp_vals)\n",
    "\n",
    "sigma_exp = 0.1*np.ones(n_exp_vals)\n",
    "\n",
    "g_exp = np.stack((flat_mat, sigma_exp)).T\n",
    "\n",
    "# ph_weights[i, j] tells how much protonation state j contributes at pH i\n",
    "# so it is normalized over the protonation states (sum over j must be 1 for every i)\n",
    "ph_weights = []\n",
    "for i in range(n_ph):\n",
    "    ph_w = np.ones(n_prot)\n",
    "    ph_w /= np.sum(ph_w)\n",
    "    ph_weights.append(ph_w)\n",
    "ph_weights = np.array(ph_weights)\n",
    "\n",
    "alphas = np.ones(n_ph)\n",
    "\n",
    "weights_ref = []\n",
    "gs = []\n",
    "\n",
    "n_frames = [100, 150, 75, 129, 4]\n",
    "\n",
    "assert len(n_frames) == n_ph, 'error on n_frames'\n",
    "\n",
    "for i in range(n_ph):\n",
    "    weights_ref.append(numpy.random.rand(n_frames[i]))\n",
    "    gs.append(numpy.random.rand(n_frames[i], n_obs))\n",
    "\n",
    "\n",
    "g_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c35e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-10.24052342, dtype=float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_gamma(lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6550bd3",
   "metadata": {},
   "source": [
    "### Gradient of Gamma and minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_gamma_gradient_fun = jax.grad(ph_gamma, argnums=0)\n",
    "\n",
    "def ph_gamma_and_grad(lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights):\n",
    "    args = (lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights)\n",
    "    gamma = ph_gamma(*args)\n",
    "    grad = ph_gamma_gradient_fun(*args)\n",
    "    return gamma, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b837b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.89620079, -0.79620078, -0.89620079, -0.48329854, -0.38329854,\n",
       "       -0.18329856, -0.86773447, -0.80662741, -0.60662742, -0.30662741,\n",
       "       -1.00662742, -0.65846141, -0.65846141], dtype=float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = (lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights)\n",
    "\n",
    "ph_gamma_gradient_fun(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights)\n",
    "\n",
    "mini = minimize(ph_gamma_and_grad, lambdas, args=args, method='BFGS', jac=True)  # , options={'gtol': gtol})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590b16aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-9.76651757, dtype=float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_gamma(lambdas, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e33de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: -91.52374329652514\n",
       "        x: [ 2.752e+01  1.752e+01 ...  4.343e+01  4.343e+01]\n",
       "      nit: 41\n",
       "      jac: [ 5.361e-06  4.801e-06 ... -2.000e-06 -2.000e-06]\n",
       " hess_inv: [[ 2.057e+01  1.864e+01 ...  2.576e+00  2.576e+00]\n",
       "            [ 1.864e+01  2.145e+01 ...  2.100e+00  2.100e+00]\n",
       "            ...\n",
       "            [ 2.576e+00  2.100e+00 ...  2.596e+01  2.496e+01]\n",
       "            [ 2.576e+00  2.100e+00 ...  2.496e+01  2.596e+01]]\n",
       "     nfev: 44\n",
       "     njev: 44"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3be4f",
   "metadata": {},
   "source": [
    "sanity check: $\\min \\Gamma$ is negative as it should be because it is the opposite of the loss function (which is always positive) in its minimum (a part from the KL term for the pH weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee3885e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.51887624,  17.51882008,  27.51887624,  30.96435588,\n",
       "        20.96430046,   0.96418962,  60.56810478,  29.01927541,\n",
       "         9.01916457, -20.98100467,  49.01938849,  43.4309016 ,\n",
       "        43.4309016 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a89137f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: -91.5237432980671\n",
       "        x: [ 2.752e+01  1.752e+01 ...  4.343e+01  4.343e+01]\n",
       "      nit: 42\n",
       "      jac: [ 4.692e-06  4.287e-06 ... -1.730e-06 -1.730e-06]\n",
       " hess_inv: [[ 2.126e+01  1.960e+01 ...  3.817e+00  3.817e+00]\n",
       "            [ 1.960e+01  2.290e+01 ...  3.846e+00  3.846e+00]\n",
       "            ...\n",
       "            [ 3.817e+00  3.846e+00 ...  2.657e+01  2.557e+01]\n",
       "            [ 3.817e+00  3.846e+00 ...  2.557e+01  2.657e+01]]\n",
       "     nfev: 44\n",
       "     njev: 44"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lambdas = np.zeros(len(lambdas))\n",
    "\n",
    "mini = minimize(ph_gamma_and_grad, new_lambdas, args=args, method='BFGS', jac=True)  # , options={'gtol': gtol})\n",
    "\n",
    "mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a04e4f",
   "metadata": {},
   "source": [
    "### full loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7f1cc",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "w_{ij}(\\vec\\pi) = \\frac{\\pi_j \\, e^{\\beta\\Delta\\mu_i N_j}}{\\sum_j \\pi_j \\, e^{\\beta\\Delta\\mu_i N_j}}\n",
    "\\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "where $e^{\\beta\\Delta\\mu_i}$ is the fugacity factor for pH n. i ($\\Delta\\mu_i$)\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{\\mathcal L} (\\vec\\pi) = -\\min_{\\vec\\lambda} \\Gamma(\\vec\\lambda;\\vec\\pi) + \\alpha D_{KL}[\\vec\\pi || \\vec\\pi_0]\n",
    "\\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- the constraint $\\pi_i \\geq 0$ can be imposed with a change of variable to the log weights $\\pi_i = e^{\\nu_i}$ (this excludes $\\pi_i =0$ but we can go arbitrarily close so it's fine); then there is the constraint $\\sum_i \\pi_i = 1$; minimizing over $\\pi_i$ can be casted to a minimization over $\\nu_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ph_weights_old(pi, fugacity, ns):\n",
    "    # this if the first input variable is the weights and not their logarithm\n",
    "    ph_weights = pi*fugacity**ns\n",
    "\n",
    "    ph_weights /= np.sum(ph_weights)\n",
    "    return ph_weights\n",
    "\n",
    "def compute_ph_weights(log_pi, log_fugacity, ns):\n",
    "    ph_weights = np.exp(log_pi + log_fugacity*ns)\n",
    "    ph_weights /= np.sum(ph_weights)\n",
    "    return ph_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98661b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ph_loss(log_pi_vec, ref_pi, alpha_pi, lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, fugacities, n_prot=[0, 1], is_fixed=True):\n",
    "    \n",
    "    # 1. compute ph_weights from pi_vec (ph_weights is a 2d array, `ph_weights[i, j]` is the probability\n",
    "    # of the protonation state `j` at pH `i`, normalized over `j` for every `i`)\n",
    "    ph_weights = []\n",
    "\n",
    "    for log_fug in log_fugacities:\n",
    "        weights = compute_ph_weights(log_pi_vec, log_fug, n_prot)\n",
    "        weights /= np.sum(weights)\n",
    "        ph_weights.append(weights)\n",
    "    \n",
    "    ph_weights = np.array(ph_weights)\n",
    "    \n",
    "    # 2. minimize Gamma function at given ph_weights\n",
    "    args = (legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights)\n",
    "\n",
    "    if not is_fixed:\n",
    "        mini = minimize(ph_gamma_and_grad, lambdas, args=args, method='BFGS', jac=True)  # , options={'gtol': gtol})\n",
    "        gamma = mini.fun\n",
    "    else:\n",
    "        gamma = ph_gamma(lambdas, *args)\n",
    "    \n",
    "    # 3. compute the loss value\n",
    "    dkl = np.sum(pi_vec*np.log(pi_vec/ref_pi))\n",
    "    loss = - gamma + alpha_pi*dkl\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66fed884",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_loss_gradient_fun = jax.grad(ph_loss, argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ph_loss_and_grad(lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, ph_weights):\n",
    "    args = (pi_vec, ref_pi, alpha_pi, lambdas, legend_matrix, gs, g_exp, weights_ref, alphas, fugacities, n_prot, is_fixed):\n",
    "    loss = ph_loss(*args)\n",
    "    grad = ph_loss_gradient_fun(*args)\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63372838",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0dd45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8942d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Simulation-data/A5mer/'\n",
    "\n",
    "ns = {}\n",
    "gs = {}\n",
    "\n",
    "for ph in [3.50, 4.00, 4.50]:\n",
    "    ns[ph] = pandas.read_csv(path + 'A5mer_pH0%.2f.occ' % ph, header=None).iloc[:, 0]\n",
    "    gs[ph]\n",
    "\n",
    "len(ns[3.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf34b705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 400 artists>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pandas.read_csv(path + 'COLVAR_REWEIGHT_0%.2f' % ph, header=3, sep=' ').iloc[:, :4]\n",
    "df.columns = ['time', 'chi', 'eRMSD', 'bias']\n",
    "\n",
    "plt.hist(df['chi'], bins=400)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e953a8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0\n",
       "         ..\n",
       "149995    1\n",
       "149996    1\n",
       "149997    1\n",
       "149998    1\n",
       "149999    1\n",
       "Name: 0, Length: 150000, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns[3.5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
